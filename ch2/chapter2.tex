% Chapter 2

\chapter{State of the art} % Main chapter title

\label{chap:Chapter2} % For referencing the chapter elsewhere, use \ref{chap:Chapter2} 

%----------------------------------------------------------------------------------------

For the \textit{State of the art} chapter, an extensive examination of studies related to multiclass imbalance in machine learning was conducted. From this review four topics of significance were identified, each worthy of a dedicated section. Each section provides an introduction to the topic and explores its relevance to multiclass imbalance training.

The first section presents a general review of the literature to explore the impact and reach of multi-class imbalance in real world scenarios. The second section addresses Class Imbalance problems, detailing how imbalance-related challenges affect predictive accuracy and discussing various balancing strategies and techniques designed to mitigate these issues. The third section focuses on classification itself, explaining how models perform classification tasks, the main types of classification algorithms, and the algorithms most commonly applied in multiclass settings. The final section examines evaluation metrics, emphasizing the importance of the confusion matrix and discussing how multiple metrics should be applied to accurately interpret the results of models trained on multiclass imbalanced datasets.

\section{Review of the Literature}

% Give examples in professional context on the impact of the issue

This section analyzes several studies addressing multi-class problems across different professional contexts. It aims to present various approaches for handling these issues in datasets with distinct characteristics to highlight the advantages of using a recommendation tool to select suitable combinations of balancing methods and classification algorithms.


A study by \cite{Iqbal2023} addresses the challenge of significant class imbalance in datasets used for deep learning models that predict disease indicators from X-ray and CT images. It emphasizes the importance of accurately identifying minority classes, as disease detection is the primary objective of such models. The researchers employed the SVM classification algorithm (see Section to categorize images in clustering and introduced a resampling technique named Three-Phase Dynamic Learning (3PDL),to handle class imbalance, combined with a parallel CNN model. The approach achieved an F1 score of 96.83 and a precision score of 96.87, demonstrating strong performance for the trained model.

Another study by \cite{abdelkhalek2023addressing} addresses the class imbalance issue in Network intrusion detection systems (NIDS) that are utilized in the detection and prevention of malicious attacks on a network. One of NIDS approaches to attack prevention, anomaly-based detection, uses machine learning to detect possible attacks. The study shows improvement in results for ADASYN + Tomek's Link resampling alongside a Multi-layer perceptron (MLP) model for classification that resulted in 99.9\% accuracy and detection rate on multi-class datasets.

A study by \cite{mutanov2021multi} examines sentiment analysis using social media data, where multi-class datasets are often highly imbalanced with a predominance of positive sentiment. The study concludes that, for the characteristics of the dataset analyzed, applying SMOTE and random oversampling in combination with decision tree, logistic regression, and random forest classifiers produced the highest classification scores and significantly improved performance compared to models trained without sampling.

%Face recognition is another domain characterized by significant class imbalance. The study by \cite{face8708977} identifies common facial features that dominate datasets compared to less frequent ones and explores the use of Cluster-based Large Margin Local Embedding technique to preserve clear class separation. When combined with  \textit{k}-nearest cluster classifiers, this approach achieved notable performance improvements over existing methods in the area.

\cite{YUAN2018160} proposes a stratified undersampling method used with a variation of AdaBoost across 11 datasets from different contexts to show improvement over existing approaches.

The study by \cite{SIDUMO2022101822} investigates the use of multiple bagging and boosting algorithms to evaluate model performance on ecological datasets with class imbalance involving various fish species. The results, assessed using recall and F1-scores, indicate that bagging classifiers such as random forest and bagCART (bagging classification trees) performed well on imbalanced data, whereas some boosting classifiers like bootCART (boosting classification trees) and AdaBoost produced weaker results and required resampling to improve performance.

\begin{table}
\caption{Summary of studies, dataset areas, classification algorithms, and class balancing methods.}
\label{tab:study_summary}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{l l l l}
\toprule
\tabhead{Study} & \tabhead{Area} & \tabhead{Classification Algorithm} & \tabhead{Class Balancing Method} \\
\midrule
Iqbal et al. (2023) & Medical imaging & SVM + CNN & Under-sampling \\
Abdelkhalek et al. (2023) & Network intrusion detection & MLP & Hybrid sampling \\
Mutanov et al. (2021) & Sentiment analysis & DT, LR, RF & Over-sampling \\
%Face recognition study & Face recognition & k-nearest cluster classifiers & Cluster-based Large Margin Local Embedding \\
Sidumo et al. (2022) & Ecological monitoring & RF, bagCART, bootCART, AdaBoost & Various Resampling Methods \\ 
Yuan et al. (2018) & Multiple domains & AdaBoost variant & Stratified undersampling \\
\bottomrule\\
\end{tabular}
}
\end{table}



A broader study by \cite{haixiang2017review} examined 527 articles related to class imbalance to illustrate the occurrence of rare instances in datasets across diverse fields, including chemical engineering, financial management, industrial manufacturing, and information technology. The study provides insights into how different disciplines address imbalance: chemical and biomedical engineering often apply ensemble classifiers with resampling, financial and management fields tend to use cost-sensitive learning instead of resampling, and information technology typically requires extensive data cleaning due to the complexity and unstructured nature of its data.

These studies indicate that multi-class imbalance affects model training across a wide range of contexts, reducing performance. As Table \ref{tab:study_summary} demonstrates, datasets from different domains exhibit distinct characteristics and achieve better results through varied balancing and classification methods, highlighting the potential value of developing a recommendation tool for managing class imbalance.

\section{Classification}

% introduction of the idea of classification, mentions the existance of different types of classifications depending on dataset, include explanation for binary classifications, multi-class for single label, and multi-class for multiple labels. Show graphs of both how classification works and how different classification relate to each other. Mention that single class won't be the focus of the dissertation.

% mention the transformation of multi-class problems into multiple binary ones. \cite{lango2022multiclass}

Classification in machine learning refers to the application of supervised learning algorithms that group data into predefined classes based on shared characteristics (\cite{IBM2025_classificationML}). These algorithms use labeled training data to predict unseen instances with similar features, supporting tasks such as image recognition, sentiment analysis, and domain-specific applications in finance and healthcare among others.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{ch2/assets/ClassificationDiagram.png}
    \caption[Taxonomy-of-imbalance-learning-techniques]{Classification Process.}
    \label{fig:classification-process}
\end{figure}

For example, consider a dataset containing banking transaction records. To train a model, the data is first preprocessed to address imbalance issues, such as generating additional samples for underrepresented classes like fraudulent transactions and removing overrepresented ones such as common payments, while preserving class boundaries as explained in Section \ref{chap:Chapter2:classImbalanceProblems}. The processed dataset is then used in a supervised classification method that groups similar samples into labeled categories. After training, the model learns to recognize data patterns associated with specific labels and can assign appropriate labels to new, unseen transactions, such as recognizing new fraudulent transaction attempts (\cite{ChakrabortyDey2024}).

In machine learning, classification is defined by the number of labels a model can predict. When only two labels are possible, such as yes and no or positive and negative, the task is binary classification. When the output can take more than two labels, the task is multi-class classification.

Within multi-class classification, tasks can be further divided into single-label and multi-label categories. In single-label classification, a model assigns only one class from the set of possible values to each unseen instance. In multi-label classification, each instance can be assigned multiple classes simultaneously.

The following subsections examine common classification algorithms and their application in multi-class classification tasks.


\subsection{Support Vector Machine Classification}

Support Vector Machine (SVM) is a classification algorithm used in supervised machine learning that has the main objective of creating a separation line (i.e. Hyperplane) to create a boundary between different classes in the data, allowing classification errors to be minimized and retain better generalization (\cite{CERVANTES2020189}).

For linear binary datasets, the optimal hyperplane for an SVM is the one that maximizes the margin. The margin is defined by the support vectors, which are the samples closest to the hyperplane on each side. The region between the lines that pass through these support vectors and run parallel to the hyperplane represents the margin.

\begin{figure}[!htbp]
    \centering
    \includegraphics[]{ch2/assets/svmhyperplane.png}
    \caption[SVM Hyperplane]{SVM Hyperplane (\cite{MathWorks_SVM_image})}
    \label{fig:svm-hyperlane}
\end{figure}

If a hyperplane cannot perfectly separate the two classes, a \textit{slack} variable is introduced to allow limited misclassification under a soft-margin formulation. This approach seeks the widest feasible margin while permitting violations when strict separation is not achievable. The \textit{C} parameter regulates this balance by controlling how strongly misclassified samples influence the objective. Higher values enforce tighter fitting with reduced tolerance for errors, while lower values allow a broader margin with increased flexibility (\cite{burges1998tutorial}).

For non-linear datasets, SVM uses kernel functions that map samples into a feature space where a separating hyperplane can be defined. The kernel transforms the data into a representation that supports linear separation. Several kernels are used depending on the scenario, including the linear kernel, the polynomial kernel, and the radial basis function kernel (\cite{GeeksforGeeks_SVM}).

SVM was originally designed for binary tasks. For multi-class classification, adaptations transform the problem into several binary decisions. Two common adaptations are one-versus-one (OVO) and one-versus-all (OVA).

\subsubsection{One-Versus-One}

In one-versus-one, a separate hyperplane is trained for every pair of classes selected from the \textit{N} classes in the dataset. Each pair forms a binary classifier, and all classifiers participate in the final decision. A voting scheme such as max-wins is used, where each classifier contributes one vote to its predicted class, and the class with the highest vote count is selected. When a tie occurs, a decision function assigns a score to each class to resolve the tie (\cite{debnath2004decision}).

\subsubsection{One-Versus-All}

In comparison, the one-versus-all approach creates N classifier where N is the number of classes in the dataset, for each classifier, the Nth class is treated as the positive class, while all other classes are treated as the negative class. A decision function is utilize to assign a value to a prediction (positive if it likely belongs to the positive class of the classifier or negative if it doesn't), the classifier with highest value determines the class (\cite{Wei991427}).

\subsection{Decision Tree Classification}

\subsection{Convolutional Neural Network}

\subsection{Naive Bayes}


\section{Class Imbalance problems}
\label{chap:Chapter2:classImbalanceProblems}
%  give an introduction to the three main balancing approaches: algorithmic approach, data preprocessing approach, feature selection approach. Show table of each approach type and some exemple methods. Talk about techniques of balancing like Over or Underssampling.

With the rapid expansion of artificial intelligence applications in recent years, the use of machine learning models has become widespread across multiple professional domains. As these applications diversify, the datasets used in each area vary significantly in composition, quality, and distribution. In many cases, certain events or classes occur far less frequently than others, creating disproportionate class representation. For instance, in bioengineering analysis, a dataset may predominantly represent a “Healthy” class, while only a few samples correspond to a specific condition such as “Skin cancer.” In such scenarios, machine learning models are often most valuable when they can accurately identify and classify these underrepresented cases, which makes their recognition essential for achieving meaningful results.

Class imbalance refers to this unequal representation of classes within a dataset. The class containing the largest number of samples is known as the \textit{majority class}, while the less frequent ones are referred to as \textit{minority class}. The imbalance may range from mild, where the difference in representation is moderate, to severe, where the majority class overwhelmingly dominates the dataset.

When training classification algorithms, the greater the imbalance, the more difficult it becomes for the model to learn the characteristics of minority classes. Classifiers inherently tend to favor the majority class, leading to biased predictions and reduced accuracy for the minority classes. As a result, the model may fail to correctly identify rare cases, instead assigning most predictions to the majority class. This behavior is particularly problematic in fields where minority classes represent the most critical scenarios, such as the aforementioned bioengineering datasets, where the accurate detection of these rare events such as identifying anomalies or diseases is often the primary objective.

To ensure that classification models produce accurate and unbiased results, various balancing methods have been developed to modify dataset distributions by adding, removing, or adjusting samples. These techniques aim to achieve a more uniform representation of all classes, allowing models to better learn the characteristics of minority classes and improve overall predictive performance. Figure \ref{fig:imbalance-learning-techniques}.  illustrates the different balancing approaches discussed in the following subsections.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{ch2/assets/Taxonomy-of-imbalance-learning-techniques.png}
    \caption[Taxonomy-of-imbalance-learning-techniques]{Imbalanced Learning Methods. (\cite{ResearchGate2025})}
    \label{fig:imbalance-learning-techniques}
\end{figure}

\subsection{Data Level Approaches}

Data-level methods focus on techniques designed to modify the dataset distribution either by increasing the number of samples in minority classes, referred to as oversampling, or by reducing the number of samples in majority classes, referred to as under sampling. Both approaches aim to achieve a more balanced dataset that allows classification algorithms to better learn the characteristics of all classes. The following subsections will describe each method in detail, outlining their underlying mechanisms, advantages, and potential limitations, as well as combined methods that use both over and under sampling to achieve balanced class representation.

\subsubsection{Over Sampling}

%Explain how it works, give examples, mention smore, adasyn and other methods, explain positives, negatives, mention possible overfitting

Over Sampling refers to the method of adding more samples of minority classes in order to achieve equal representation between classes and allow for classification algorithms that tend to be bias to majority classes to properly identify minority classes. 



\begin{itemize}
    \item \textbf{Random Over Sampling}: Random sampling is a technique in which samples from the minority class are randomly selected and duplicated without modification until the dataset reaches a relatively balanced state. While this method is simple and effective in reducing class imbalance, the new sample it creates do not contain any new information regarding it's minority class. Instead, it amplifies specific samples of the class, which can lead to overfitting by causing the model to learn narrow patterns that fail to generalize, which would reduce it's overall accuracy.

    \item \textbf{SMOTE}: \textit{Synthetic Minority Oversampling Technique} (SMOTE) differs from random sampling by generating synthetic samples rather than duplicating existing ones. The method selects a sample from the minority class and identifies its \textit{k} nearest neighbors. Based on these neighbors, new samples are interpolated within the defined feature space. This approach produces new data points that remain within the minority class region, with the goal of reduce the imbalance ratio, a ratio for majority to minority samples. A key limitation of SMOTE lies in its sensitivity to the distribution of neighboring points. When neighbors are too distant or in insufficient amounts, the generated samples may introduce noise, fall outside the minority class boundaries or increase the risk of overfitting (\cite{Chawla2002}).
    
    \item \textbf{ADASYN}: \textit{The Adaptive Synthetic} (ADASYN) method introduces an adaptive approach to generating synthetic samples compared to SMOTE. Its main distinction lies in the way it distributes newly generated samples among the minority classes. ADASYN focuses on creating more synthetic samples for minority instances that are harder to learn, while producing fewer samples for those that are easier to classify. The difficulty level is determined by calculating the number of nearest neighbors belonging to the majority class, and a proportional ratio is then applied to quantify how difficult each minority instance is to learn. This adaptive mechanism enables the model to emphasize more complex decision regions, leading to improved learning balance across classes (\cite{He2008}).

    
\end{itemize}

The use of oversampling can be beneficial, as it provides a straightforward way to generate additional samples that help mitigate dataset imbalance and reduce the bias that classification algorithms exhibit toward majority classes. However, oversampling also introduces certain drawbacks. The expansion of the dataset increases computational cost during training, and synthetic samples may lead to overfitting (\cite{Ying_2019}), a scenario in which the model learns patterns specific to the generated data rather than generalizable characteristics of the minority class. Consequently, this may cause misclassifications of real minority samples and a reduction in overall model performance when applied to unseen data.

\subsubsection{Under Sampling}

%Explain how it works, give examples
Under sampling refers to the method of reducing the number of samples from the majority class in imbalanced datasets to achieve a more balanced class distribution. This approach aims to mitigate the bias introduced by overrepresented classes, allowing the learning algorithm to focus more effectively on minority classes (\cite{MastersInDataScience_Undersampling}).

\begin{itemize}
    \item \textbf{Random Under Sampling}: \textit{Random Under Sampling} is a technique where samples from the majority class are randomly removed until the dataset reaches an acceptable level of balance (\cite{Japkowicz2002}). While this approach reduces training time and simplifies the dataset, it can also introduce drawbacks. The random elimination of samples may result in the loss of important information or class-defining characteristics, weakening the model’s classification performance.
    
    \item \textbf{Editing Nearest Neighbor}: The \textit{Editing Nearest Neighbor} (ENN) method looks for the \textit{k} nearest neighbors of each sample and evaluates whether the majority of these neighbors belong to a different class. If the sample is surrounded predominantly by instances of another class, it is removed from the dataset (\cite{wilson1972asymptotic}). This method differs from other under sampling methods as it is often used in addition to another method, such as SMOTE, as a way to denoise the dataset after synthetic samples are introduced. 
    This method differs from other under-sampling techniques in that it is frequently applied in combination with other approaches, such as SMOTE with the primary purpose to denoise the dataset by removing overlapping samples after synthetic instances have been added, improving classification performance.
    

    \item \textbf{Condensed Nearest Neighbor:} The Condensed Nearest Neighbor (CNN) method creates a subset, called \textit{Store}, from the original dataset \textit{D}, containing samples of a defined \textit{k} nearest neighbors. The goal is for \textit{Store} to preserve the class distribution of \textit{D}, ensuring that the majority class in \textit{Store} matches that of the original dataset. If this condition is not met, new samples are iteratively added to \textit{Store} until consistency is achieved, or all samples from \textit{D} have been included, effectively making \textit{Store} identical to \textit{D} (\cite{hart1968condensed}).

    
    \item \textbf{Tomek’s Links:} This method identifies pairs of samples from different classes that are each other’s nearest neighbors, with their proximity suggesting that they lie near the decision boundary. These instances are typically difficult for classifiers to distinguish correctly, as they often represent ambiguous regions between classes. By removing the majority sample or both samples in a Tomek Link pair, the method helps to clean the dataset and create a clearer separation between classes (\cite{Tomek1976}). 
    
    Tomek’s Link assumes a binary dataset structure, limiting its effectiveness in multi-class contexts. To address this, different methods to adapt Tomek's Link for multi-class and multi-label datasets have been developed, as an example, an study by \cite{PEREIRA202095} proposed the \textit{Multi-Label Tomek Link} (MLTL), a method that can function as either an undersampling technique or a post-processing cleaning step for multi-class datasets. It uses a \textit{MeanIR} metric to identify majority class samples for removal and the \textit{Adjusted Hamming Distance} to measure dissimilarities between neighboring label sets. A dynamic threshold (\textit{TH}) based on the \textit{MeanIR} defines how distinct two instances must be to form a Tomek Link, with lower thresholds applied to more imbalanced datasets.

\end{itemize}

The application of under sampling methods can improve classification by reducing dataset size and computational load, which can lead to faster training and simplified model structures. However, these methods also pose risks, particularly the occurrence of \textit{underfitting}, where excessive data removal oversimplifies the dataset, preventing the model from generalizing efficiently and resulting in low accuracy on both training and unseen data (\cite{IBM2025_underfitting}). For this reason, under sampling is commonly combined with other balancing techniques, serving as a post-processing step to remove noisy samples near class boundaries, to enhancing dataset quality and improving model performance.


\subsubsection{Combined Methods}

Combined methods that integrate both over sampling and under sampling techniques can also be applied to achieve a more balanced and cleaner dataset. In such approaches, over-sampling is first used to generate synthetic samples and increase minority class representation. Subsequently, an under-sampling method is applied to eliminate potential noise introduced during the over-sampling phase and to refine class boundaries. This sequential process helps maintain diversity within minority classes while preventing overfitting and improving the overall performance within certain contexts. (\cite{Rendon2020}).

One combination, \textit{SMOTE+Tomek's Link} (\cite{zeng7563084}) applied in the preprocessing step uses SMOTE to generate synthetic samples for the minority class and removes borderline instances using Tomek’s Link. This combination preserves class boundaries and yields higher evaluation metrics than methods without preprocessing or those applying only SMOTE.

Another approach, \textit{RFMSE} (\cite{XU2020103465}) used with the Random Forest classification algorithm, combines a modified version of SMOTE, called \textit{M-SMOTE}, to dynamically adjust the oversampling process. Instead of relying solely on the imbalance ratio, M-SMOTE uses the misclassification rate from Random Forest to determine the number of synthetic samples to generate. After oversampling, the \textit{Edited Nearest Neighbor} (ENN) method is applied to remove majority class samples if the classification evaluation of the oversampled dataset does not achieve satisfactory balance. This adaptive mechanism allows RFMSE to optimize sample generation and data cleaning simultaneously, resulting in improved performance shown compared to conventional resampling techniques.

Experimental results for other hybrid approaches presented in multiple studies, such as SMOTE+ENN* (\cite{Rendon2020}), SMOTE-RSB (\cite{Ramentol2012}) and NCL+A-SUWO (\cite{Choirunnisa8864335}) among others, indicate that across various domains and dataset configurations, the use of combined sampling strategies often yields noticeable improvements in both efficiency and predictive accuracy when compared to isolated over or under sampling methods.


\subsection{Algorithmic Level Approaches}

\subsection{Cost Sensitive Approaches}

Cost sensitive methods for

\subsection{Ensemble Learning Approaches}

\subsection{Multi Class Decomposition Approaches}

%talk about OVO, OVA and variations, explain the need to decompose a multi-class issue into multiple binary ones. (What makes multi-class imbalanced problems difficult? An experimental study) lango2022

\section{Meta-learning approaches for method recommendation}

\section{Analysis Metrics}
